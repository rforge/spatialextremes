\documentclass[a4paper]{report}
\usepackage{Sweave}
\usepackage[utf8]{inputenc}
\usepackage{fullpage}
\usepackage{amsmath,amsfonts}
\usepackage{hyperref}
\usepackage[square]{natbib}

\setlength{\parskip}{0.7ex plus0.1ex minus0.1ex}
\setlength{\parindent}{0em}

\renewcommand{\floatpagefraction}{0.95}
\renewcommand{\textfraction}{0.05}

\begin{document}
% \VignetteIndexEntry{A R Package for Modelling Spatial Extremes} 
% \VignetteDepends{SpatialExtremes,RandomFields}
% \VignetteKeyword{Extreme Value Theory, Spatial Extremes, Max-stable processes} 
% \VignettePackage{SpatialExtremes}

\begin{titlepage}
  \vspace*{2cm}
  \begin{center}
    \LARGE SpatialExtremes: A R Package for Modelling Spatial Extremes\\
    \vspace{1em}
    \Large Mathieu Ribatet\\
    \vspace{1em}
    Copyright \copyright{2008}\\
    \vspace{2em}
    \large
    Chair of Statistics\\
    École Polytechnique Fédérale de Lausanne\\
    Switzerland
  \end{center}
  \vspace{1cm}
  \begin{center}
<<echo=FALSE,fig=TRUE>>=
library(SpatialExtremes)
library(RandomFields)
image(volcano, col = terrain.colors(100), xaxt = "n", yaxt="n")
contour(volcano, add = TRUE)
@ 
  \end{center}
\end{titlepage}


\pagenumbering{roman}
\normalsize

\tableofcontents
\listoftables
\listoffigures

\pagenumbering{arabic}

\chapter*{Introduction}
\label{cha:introduction}
\addcontentsline{toc}{chapter}{Introduction}


\section*{What is the SpatialExtremes package?}
\label{sec:what-spat-pack}

The \textbf{SpatialExtremes} package is an add-on package for the R
\citep{Rsoft} statistical computing system. It provides functions for
the analysis of spatial extremes.

All comments, criticisms and queries on the package or associated
documentation are gratefully received.

\section*{Obtaining the package/guide}
\label{sec:obta-pack}

The package can be downloaded from CRAN (The Comprehensive R Archive
Network) at \url{http://cran.r-project.org/}.  This guide (in pdf)
will be in the directory \verb+SpatialExtremes/doc/+ underneath
wherever the package is installed. You can get it by invoking
<<eval=FALSE>>=
vignette("SpatialExtremesGuide")
@ 

\section*{Contents}

This guide contains examples on the use of the
\textbf{SpatialExtremes} package. \textbf{to be continued}

\section*{Citing the package/guide}

To cite this guide or the package in publications please use the
following bibliographic database entry.
\begin{verbatim}
\@Manual{your_key,
  title = {SpatialExtremes: A R package for Modelling Spatial Extremes},
  author = {Ribatet, M.},
  year = {2008},
  month = {May},
  url = {http://cran.r-project.org/}
}
\end{verbatim}

\section*{Caveat}

I have checked these functions as best I can but, as ever, they may
contain bugs.  If you find a bug or suspected bug in the code or the
documentation please report it to me at
\href{mailto:mathieu.ribatet@epfl.ch}{mathieu.ribatet@epfl.ch}.
Please include an appropriate subject line.

\section*{Legalese}

This program is free software; you can redistribute it and/or
modify it under the terms of the GNU General Public License
as published by the Free Software Foundation; either version 3
of the License, or (at your option) any later version.

This program is distributed in the hope that it will be useful,
but without any warranty; without even the implied warranty of
merchantability or fitness for a particular purpose.  
See the GNU General Public License for more details.


A copy of the GNU General Public License can be obtained from 
\url{http://www.gnu.org/copyleft/gpl.html}.

\section*{Acknowledgements}

This work has been supported by the Competence Center Environment and
Sustainability (\href{http://www.cces.ethz.ch/index}) within the
\href{http://www.cces.ethz.ch/projects/hazri/EXTREMES}{EXTREMES}
project. I would like to thank Simone Padoan for his support while
trying to get the ``awful'' gradient in Section
\ref{sec:with-ordinary-gev}.

\chapter{An Introduction to Max-Stable Processes}
\label{cha:an-introduction-max}

A max-stable process $Z(\cdot)$ is the limit process of maxima of
independent identically distributed random fields $Y_i(x)$, $x \in
\mathbb{R}^d$. Namely, for suitable $a_n(x) > 0$ and $b_n(x) \in
\mathbb{R}$,
\begin{equation}
  \label{eq:maxstab-def}
  Z(x) = \lim_{n \rightarrow +\infty} \frac{\max_{i=1}^n Y_i(x) -
    b_n(x)}{a_n(x)}, \qquad x \in \mathbb{R}^d
\end{equation}
Note that \eqref{eq:maxstab-def} does not ensure that the limit
exists. However, provided it does and from \eqref{eq:maxstab-def}, we
can see that max-stable processes might be appropriate models for
modelling annual maxima of spatial data.

Currently, there are two different characterisations of a max-stable
process. The first one, often referred to the \emph{rainfall-storm}
model, as first been introduced by \citet{Smith1991}. More recently,
\citet{Schlather2002} introduced a new characterisation of a
max-stable process allowing for a random shape.

It is out of the scope of this document to describe fully the main
differences between the two canonical constructions. We will restrict
our attention to the analytical definitions of these two
constructions. 

Unfortunately, closed forms for the density of these two models are
only known for two different points in $\mathbb{R}^d$. Consequently,
fitting max-stable processes to data is not straightforward and the
SpatialExtremes package provides convenient tools for it.

\section{The Smith's Characterisation}
\label{sec:smiths-char}

The Smith's characterisation\footnote{There's another form of the
  Smith's model that uses a Student distribution instead of the Normal
  one. However, it is not currently implemented.} of a max-stable
process is given by:
\begin{equation}
  \label{eq:smith}
  \Pr[Z_1 \leq z_1, Z_2 \leq z_2] = \exp\left[-\frac{1}{z_1} \Phi
    \left(\frac{a}{2} + \frac{1}{a} \log \frac{z_2}{z_1} \right) -
    \frac{1}{z_2} \Phi \left(\frac{a}{2} + \frac{1}{a}
      \log\frac{z_1}{z_2} \right) \right]
\end{equation}
where $\Phi$ is the standard normal cumulative distribution function
and, for two given locations \#1 and \#2  
\begin{equation*}
  a^2 = \Delta x^T \Sigma^{-1} \Delta x \quad \text{and} \quad 
  \Sigma = 
  \begin{bmatrix}
    cov_{11} & cov_{12}\\
    cov_{12} & cov_{22}
  \end{bmatrix}
\end{equation*}
where $\Delta x$ is the distance vector between location \#1 and
location \#2.

The derivation of the density is reported in section
\ref{sec:density-computation-smith}.

\section{The Schlather's Characterisation}
\label{sec:schl-char}

The Schlather's characterisation of a max-stable process is given by:
\begin{equation}
  \label{eq:schlather}
  \Pr[Z_1 \leq z_1, Z_2 \leq z_2] = \exp\left[-\frac{1}{2}
    \left(\frac{1}{z_1} + \frac{1}{z_2} \right) \left(1 + \sqrt{1 - 2
        (\rho(h) + 1) \frac{z_1 z_2}{(z_1 + z_2)^2}} \right) \right]
\end{equation}
where $h$ is the distance between location \#1 and location \#2 and
$\rho(h)$ is a valid correlation function such as $-1 \leq \rho(h)
\leq 1$.

Currently, there is three types of covariance functions implemented:

\bigskip
\begin{tabular}{ll}
  \textbf{Whittle-Matérn} & $\rho(h) =
  \frac{2^{1-smooth}}{\Gamma(smooth)} \left(\frac{h}{scale}
  \right)^{smooth} K_{smooth}\left(\frac{h}{scale} \right)$\\ 
  \textbf{Cauchy} & $\rho(h) = \left[1 + \left(\frac{h}{scale}
    \right)^2 \right]^{-smooth}$\\
  \textbf{Powered Exponential} & $\rho(h) = \exp\left[-
    \left(\frac{h}{scale} \right)^{smooth} \right]$
\end{tabular}
\bigskip

where $h$ is the distance between locations \#1 and \#2, $scale$ and
$smooth$ are the scale and smooth parameter of the covariance
function, $\Gamma$ is the gamma function and $K_{smooth}$ is the
modified Bessel function of the third kind with order $smooth$.

The derivation of the density is reported in section
\ref{sec:density-computation-schlather}.

\chapter{Fitting a Max-Stable Process to Data}
\label{sec:fit-maxstab}

As stated in the previous chapter, the densities of the two max-stable
characterisations are only known for two different locations. The
strategy used in the package is to use pairwise-likelihood instead of
the ``full'' likelihood. Namely, the log pairwise-likelihood is given
by:
\begin{equation}
  \label{eq:lplik}
  \ell_p(\mathbf{y};\psi) = \sum_{i<j} \sum_{k=1}^{n_{i,j}}
  f(y_k^{(i)}, y_k^{(j)})
\end{equation}
where $\mathbf{y}$ is the data available on the whole region,
$n_{i,j}$ is the number of common observations between sites $i$ and
$j$, $y_k^{(i)}$ is the $k$-th observation of the $i$-th site and
$f(\cdot, \cdot)$ is the bivariate distribution of the max-stable
process - see Annex~\ref{cha:dens-grad-comp} for the analytical forms.

Consequently, the max-stable process is fitted to data by maximizing
the log pairwise-likelihood\footnote{This is why the fitting procedure
  is time consuming.}. Properties of the maximum pairwise likelihood
estimator are well known \citep{Lindsay1988,Cox2004}. In particular,
because each pairwise score equation is unbiased, the sum of these
score equations is unbiased and lead to consistent estimations.

\section{Assuming Unit Fréchet Margins}
\label{sec:simple-case-study}

To start working with the SpatialExtremes package, let consider a
simple case study for which each location is unit Fréchet
distributed. M. Schlather developed a R package called
\emph{RandomFields} to simulate spatial fields from a max-stable
process. Consequently, all we need is to define the coordinate of each
location as well as the parameters of the covariance function in
equation \eqref{eq:schlather}.

<<>>=
library(RandomFields)
n.site <- 40
locations <- matrix(runif(2*n.site, 0, 10), ncol = 2)
colnames(locations) <- c("lon", "lat")

ms0 <- MaxStableRF(locations[,1], locations[,2], grid=FALSE, model="wh",
param=c(0,1,0,30, 1.2), maxstable="extr", n = 80)
ms0 <- t(ms0)
@

For this application, the covariance function is taken to be the
Whittle-Matérn covariance function with scale and smooth parameters
equal to 30 and 1.2 respectively. The locations are distributed
uniformly on the square $[0,10]^2$.

To fit a max-stable process assuming unit Fréchet all we have to do is
to invoke:
<<>>=
fitmaxstab(ms0, locations, cov.mod = "whitmat", fit.marge = FALSE)
@ 

From this output, we can see that we indeed use the Schlather's
representation with a Whittle-Matérn covariance function. The
convergence was successful and the estimates of the covariance
function are accessible. Note that large deviations from the
theoretical values are not fatal as the parameters of the
Whittle-Matérn covariance function are far from orthogonal. Thus, the
scale and smooth estimates may be totally different while leading
(approximately) to the same covariance function.

When using the Whittle-Matérn covariance function, it is
sometimes preferable to fix the smooth parameter using prior knowledge
on the process smoothness. This can be done by:
<<>>=
fitmaxstab(ms0, locations, cov.mod = "whitmat", smooth = 1.2, fit.marge = FALSE)
@ 

Despite the Whittle-Matérn is a flexible covariance function, one may
want to consider other types of covariance functions. This is achieved
by invoking:
<<eval=FALSE>>=
fitmaxstab(ms0, locations, cov.mod = "cauchy", fit.marge = FALSE)
fitmaxstab(ms0, locations, cov.mod = "powexp", fit.marge = FALSE)
@ 

One may also consider the Smith's characterisation instead of the
Schlather's one:
<<eval=FALSE>>=
fitmaxstab(ms0, locations, cov.mod = "gauss", fit.marge = FALSE)
@ 

Obvisously, for each covariance model, one can fix any parameter; so
that all the two following codes are valid:
<<eval=FALSE>>=
fitmaxstab(ms0, locations, cov.mod = "gauss", cov12 = 0, fit.marge = FALSE)
fitmaxstab(ms0, locations, cov.mod = "cauchy", scale = 30, fit.marge = FALSE)
@ 

Note that passing \verb|fit.marge = TRUE| in all the previous codes
will result in fitting the GEV parameters for each location. However,
be careful as it will be really CPU demanding as there will be
\verb|3 n.site + p| parameters to estimate - where \verb|p| is the
number of parameters for the covariance part.

\section{With Unknown GEV Margins}
\label{sec:with-unknown-gev}

In practice, our observations will never distributed from a unit
Fréchet distribution so that the previous section won't help much with
concrete applications. One way to avoid this problem is to fit a GEV
to each location and then transform all data to unit Fréchet. This is
done using the \verb|gev2frech| function and the following code:
<<>>=
x <- c(2.2975896, 1.6448808, 1.3323833, -0.4464904, 2.2737603, -0.2581876, 9.5184398, -0.5899699, 0.4974283, -0.8152157)
gev2frech(x, 1, 2, .2)
@ 

The drawback of this approach is that standard errors are definitively
lost as the margins are first fitted and then the covariance
structure. Consequently, the standard errors related to the covariance
function are underestimated as we suppose that data are originally
unit Fréchet.

Fortunately, the SpatialExtremes solves this problem by fitting in
\emph{one step} both GEV and covariance parameters. This could be done
in two ways. First, one can pass the option \verb|fit.marge = TRUE|.
However, as said in the previous section this will be really
time consuming. Another drawback is that prediction at ungauged
location won't be possible.

Another way may be to fit a \emph{response surface} for the GEV
parameters. Currently, the response surfaces allowed by the package
are polynomial surfaces or a penalized smoothing spline\footnote{this
  is an exclusive ``or'' i.e. a response surface with a polynomial and
  a spline is not possible}.

The SpatialExtremes package defines response surfaces using the
\emph{R formula} approach e.g.
<<eval=FALSE>>=
y ~ lat + I(lon^2)
@ 
for a polynomial surface and
<<eval=FALSE>>=
n.knots <- 5
knots <- quantile(locations[,2], prob = 1:n.knots/(n.knots+1))
y ~ rb(lat, knots = knots, degree = 3, penalty = .5)
@
for a penalized smoothing spline with degree 3, 5 knots and a penalty
coefficient (or smoothing parameter) equal to 0.5. \textbf{need to
  write an annex for the penalized smoothing splines}

Let start with a simple polynomial surface. For this purpose, we need
to simulate a max-stable process and then transform the observations
to the desired GEV scale. This could be done by the following lines:
<<>>=
n.site <- 20
locations <- matrix(runif(2*n.site, 0, 10), ncol = 2)
colnames(locations) <- c("lon", "lat")

sigma = matrix(c(100, 25, 25, 220),ncol = 2)
sigma.inv = solve(sigma)
sqrtCinv = t(chol(sigma.inv))
model = list(list(model = "gauss", var = 1,
aniso = sqrtCinv / 2))
ms0 <- MaxStableRF(locations[,1], locations[,2],
grid=FALSE, model=model,
maxstable="Bool",
n = 50)
ms1 <- t(ms0)
param.loc <- -10 + 2 * locations[,2]
param.scale <- 5 + 2 * locations[,1] + locations[,2]^2
param.shape <- rep(0.2, n.site)

for (i in 1:n.site)
ms1[,i] <- param.scale[i] * (ms1[,i]^param.shape[i] - 1) / param.shape[i] + param.loc[i]
@ 

Once the data are appropriately generated, we need to define the
response surface for the fitted max-stable model. This is done
invoking:
<<>>=
loc.form <- y ~ lat
scale.form <- y ~ lon + I(lat^2)
shape.form <- y ~ 1
@ 
Lastly, one can easily fit the model to data using:
<<>>=
fitmaxstab(ms1, locations, "gauss", loc.form = loc.form, scale.form = scale.form, shape.form= shape.form)
@ 

If we want to fit a spline for the location GEV parameter while
preserving the polynomials for the scale and shape parameters, this
will require a little more steps as the knots and the penalty
coefficient must be defined\footnote{Currently, an automatic criteria
  for defining the ``best'' penalty coefficient does not exist.}.
<<>>=
n.knots <- 5
knots <- quantile(locations[,2], 1:n.knots/(n.knots+1))
loc.form <- y ~ rb(lat, knots = knots, degree = 3, penalty = .5)
fitmaxstab(ms1, locations, "gauss", loc.form = loc.form, scale.form = scale.form, shape.form= shape.form)
@ 

Obviously, all these steps still remain valid when fitting the
Schlather's characterisation. Note that you can fix any parameter as
before for example, if one want to suppose that \verb|scaleCoeff3 = 1|,
this is done by invoking the following line:
<<eval=FALSE>>=
fitmaxstab(ms1, locations, "powexp", loc.form = loc.form, scale.form = scale.form,
           shape.form= shape.form, scaleCoeff3 = 1)
@ 

Please note that when using 3 smoothing splines for the GEV
parameters, you might have to tweak the \verb|ndeps| option in the
\verb|optim| function:
<<eval=FALSE>>=
fitmaxstab(ms1, , locations, "powexp", loc.form = loc.form,
           scale.form = scale.form, shape.form= shape.form,
           control = list(ndeps = rep(10^-4, n.par)))
@ 
where \verb|ndeps| is the number of parameters to be estimated.

\section{Assessing Uncertainties}
\label{sec:assess-uncert}

As stated in section~\ref{sec:fit-maxstab}, because the model is
fitted by maximizing the pairwise likelihood instead of the ``full''
likelihood, the model is \emph{misspecified}. Consequently, the
maximum pairwise likelihood estimator is still asymptotically normally
distributed but with a different asymptotic covariance matrix. Namely,
the maximum pairwise likelihood estimator $\psi_p$ satisfies the
following relation:
\begin{equation}
  \label{eq:lplikAsymp}
  \psi_p \sim \mathcal{N}\left(\psi, H(\psi)^{-1} J(\psi)
    H(\psi)^{-T} \right), \qquad n \rightarrow +\infty
\end{equation}
where $H(\psi) = \mathbb{E}[\nabla^2 \ell_p(\psi;\mathbf{Y})]$ and
$J(\psi) = \mbox{Var}[\nabla \ell_p(\psi;\mathbf{Y})]$, where the
expectations are with respect to the ``full'' density.

In practice, to get the standard errors we need to get efficient
estimates of $H(\psi)$ and $J(\psi)$. The estimation of the former is
straightforward and is given by $\hat{H}(\hat{\psi}_p) = \nabla^2
\ell_p(\hat{\psi}_p;\mathbf{y})$; that is the Hessian matrix evaluated
at $\hat{\psi}_p$. 

The estimation of $J(\psi)$ can be done in two different ways. First,
it can be estimated using the ``naive'' estimator
$\hat{J}(\hat{\psi}_p) = \nabla \ell_p(\hat{\psi}_p;\mathbf{y})
{\ell_p(\hat{\psi}_p;\mathbf{y})}^T$. In the SpatialExtremes package,
this estimator is tagged \verb|grad| as it uses the gradient of the
log pairwise likelihood. Another estimator is given by noticing that
$J(\psi)$ corresponds to the variance of the pairwise score equations
$\ell_p(\psi;\mathbf{Y}) = 0$. Consequently, a second estimator,
tagged \verb|score|, is given by the sample variance of each
contribution to the pairwise score function. Note that the second
estimator is only accessible if independent replications of
$\mathbf{Y}$ are available\footnote{which will mostly be the case for
  spatial extremes.}.

The standard errors are available by invoking the following two lines:
<<echo=FALSE>>=
n.site <- 20
locations <- matrix(runif(2*n.site, 0, 10), ncol = 2)
colnames(locations) <- c("lon", "lat")

sigma = matrix(c(100, 25, 25, 220),ncol = 2)
sigma.inv = solve(sigma)
sqrtCinv = t(chol(sigma.inv))
model = list(list(model = "gauss", var = 1, aniso = sqrtCinv / 2))
ms0 <- MaxStableRF(locations[,1], locations[,2], grid=FALSE, model=model,
                   maxstable="Bool", n = 50)
ms0 <- t(ms0)
@ 
<<>>=
fitmaxstab(ms0, locations, cov.mod = "gauss", fit.marge = FALSE, std.err.type = "score")
@ 

<<eval=FALSE>>=
fitmaxstab(ms0, locations, cov.mod = "gauss", fit.marge = FALSE, std.err.type = "grad")
@ 


\chapter{Manipulating and Visualising Fitted Models}
\label{cha:manip-visu-fitt}

\section{Prediction of the GEV parameters}
\label{sec:pred-gev-param}

Once the model is fitted, one may want to get the estimates of the GEV
parameters at any locations. This is achieved using the
\textsl{predict} function:
<<echo=FALSE>>=
n.site <- 20
locations <- matrix(runif(2*n.site, 0, 10), ncol = 2)
colnames(locations) <- c("lon", "lat")

sigma = matrix(c(100, 25, 25, 220),ncol = 2)
sigma.inv = solve(sigma)
sqrtCinv = t(chol(sigma.inv))
model = list(list(model = "gauss", var = 1, aniso = sqrtCinv / 2))
ms0 <- MaxStableRF(locations[,1], locations[,2], grid=FALSE, model=model, maxstable="Bool",n = 50)
ms1 <- t(ms0)
param.loc <- -10 + 2 * locations[,2]
param.scale <- 5 + 2 * locations[,1] + locations[,2]^2
param.shape <- rep(0.2, n.site)

for (i in 1:n.site)
ms1[,i] <- param.scale[i] * (ms1[,i]^param.shape[i] - 1) / param.shape[i] + param.loc[i]

loc.form <- y ~ lat
scale.form <- y ~ lon + I(lat^2)
shape.form <- y ~ 1
@ 
<<>>=
fitted <- fitmaxstab(ms1, locations, "gauss", loc.form = loc.form, scale.form = scale.form, shape.form = shape.form)
predict(fitted)
@ 

If one want to get estimates of the GEV parameters at an ungauged
locations, this is done by adding a matrix giving the new
coordinates. Be careful, if new coordinates are supplied, the column
names of the new coordinates should match with the one of the original
coordinates. For our application, this could be done as follows:
<<>>=
new.coord <- cbind(3:6, 7:10)
colnames(new.coord) <- c("lon", "lat")
predict(fitted, new.coord)
@ 

\section{Visualising the Extremal Coefficient}
\label{sec:visu-extr-coeff}

The extremal coefficient is a useful quantity to assess the dependence
between two locations $x_1$ and $x_2 \in \mathbb{R}^d$. Assuming that
the data could be modeled by a max-stable process with unit Fréchet
margin, the extremal coefficient $\theta(||x_1 - x_2||)$ satisfies:
\begin{equation}
  \label{eq:extcoeff}
  \Pr\left[Z(x_1) \leq z, Z(x_2) \leq z\right] = \exp\left(-
    \frac{\theta(||x_1 - x_2||)}{z} \right)
\end{equation}
where $1 \leq \theta(||x_1 - x_2||) \leq 2$ with the lower and upper
bounds corresponding to complete dependence and independence between
locations $x_1$ and $x_2$.

Consequently, the extremal coefficient function $\theta(\cdot)$ is a
natural way to know how evolves the dependence between extremes in
space.

The closed form of the extremal coefficient function is known for both
Smith's and Schlather's characterisations. Namely, the function is
given by:

\bigskip
\begin{tabular}{ll}
  \textbf{Smith} & $\theta(||x_1 - x_2||) = 2
  \Phi\left(\frac{\sqrt{(x_1 - x_2)^T \Sigma^-1 (x_1 - x_2)}}{2}
  \right)$\\
  \textbf{Schlather} & $\theta(||x_1 - x_2||) = 1 + \sqrt{\frac{1 -
      \rho(||x_1 - x_2||)}{2}}$
\end{tabular}
\bigskip

The SpatialExtremes package allows to plot the evolution of the
extremal coefficient function using the \verb|extcoeff| function - see
Fig.~\ref{fig:extcoeff}.
<<label=extcoeff>>=
extcoeff(fitted)
@ 

\begin{figure}
  \centering
<<fig=TRUE,echo=FALSE>>=
<<extcoeff>>
@ 
  \caption{Evolution of the extremal coefficient function in $\mathbb{R}^2$.}
  \label{fig:extcoeff}
\end{figure}

\section{Visualising the Covariance Function}
\label{sec:visu-covar-funct}

Another way to assess how evolves the dependence between extremes as
the distance increases is to plot the covariance function. This is
done using the \verb|covariance| function. Note that this function is
only available for the Schlather's characterisation.

Basically, there are two ways to call the \verb|covariance|
function. We can call it once we have fitted a max-stable process or
by specifying directly the covariance parameters.

For illustration purpose, Fig.~\ref{fig:covfun} compares the fitted
covariance function to the theoretical one on a new artificial
example.

<<label=covfun>>=
n.site <- 30
locations <- matrix(runif(2*n.site, 0, 10), ncol = 2)
colnames(locations) <- c("lon", "lat")

ms0 <- MaxStableRF(locations[,1], locations[,2], grid=FALSE, model="cauchy",
param=c(0,1,0,30, 1.2), maxstable="extr", n = 60)
ms1 <- t(ms0)

param.loc <- -10 + 2 * locations[,2]
param.scale <- 5 + 2 * locations[,1] + locations[,2]^2
param.shape <- rep(0.2, n.site)

##Transform the unit Frechet margins to GEV 
for (i in 1:n.site)
ms1[,i] <- param.scale[i] * (ms1[,i]^param.shape[i] - 1) /
param.shape[i] + param.loc[i]

##Define a model for the GEV margins to be fitted
##shape ~ 1 stands for the GEV shape parameter is constant
##over the region
loc.form <- loc ~ lat
scale.form <- scale ~ lon + I(lat^2)
shape.form <- shape ~ 1

fitted <- fitmaxstab(ms1, locations, "cauchy", loc.form, scale.form,
shape.form)

covariance(fitted, ylim = c(0,1))
covariance(scale = 30, smooth = 1.2, cov.mod = "cauchy", col = 3, add = TRUE)
legend("topright", c("Fitted","Theo"), lty = 1, col = c(1,3), inset = .05)
@ 

\begin{figure}
  \centering
<<fig=TRUE,echo=FALSE>>=
<<covfun>>
@ 
  \caption{Comparison between the fitted covariance function and the
    theoretical one.}
  \label{fig:covfun}
\end{figure}

Note that one can also compute the covariance at a given distance by invoking:
<<>>=
rbind(covariance(fitted, dist = seq(0,100, 25))$cov.val,
covariance(scale = 30, smooth = 1.2, cov.mod = "cauchy", dist = seq(0,100, 25))$cov.val)
@ 

\section{Producing a map of the GEV parameters and return levels}
\label{sec:poroducing-map-gev}

Most often, practitioners will like to have a map of the GEV
parameters or a map of a return level with a given return period. This
is done using the \verb|map| function.

To illustrate this feature, let start with a brand new application.
<<>>=
n.site <- 30
locations <- matrix(runif(2*n.site, 0, 10), ncol = 2)
colnames(locations) <- c("lon", "lat")

##Simulate a max-stable process - with unit Fréchet margins
ms0 <- MaxStableRF(locations[,1], locations[,2], grid=FALSE, model="wh",
                   param=c(0,1,0,30, .5), maxstable="extr", n = 40)
ms0 <- t(ms0)
ms1 <- ms0

##Now define the spatial model for the GEV parameters
fun.loc <- function(x)
  4.26 * exp(-x) * (1 - exp(-x)) * (1 - 3 * exp(-x))
fun.scale <- function(x)
   2 * sin(pi * x / 4) + 10
fun.shape <- function(x)
  (fun.scale(x) - 7) / 15

param.loc <- fun.loc(locations[,1])
param.scale <- fun.scale(locations[,2])
param.shape <- fun.shape(locations[,1])

##Transform the unit Fréchet margins to GEV 
for (i in 1:n.site)
  ms1[,i] <- param.scale[i] * (ms1[,i]^param.shape[i] - 1) /
  param.shape[i] + param.loc[i]

##Define a model for the GEV margins to be fitted
n.knots <- 7
knots.lon <- quantile(locations[,1], 1:n.knots / (n.knots+1))
knots.lat <- quantile(locations[,2], 1:n.knots / (n.knots+1))
loc.form <- loc ~ rb(lon, degree = 3, knots = knots.lon,
                     penalty = .2)
scale.form <- scale ~ rb(lat, degree = 3, knots = knots.lat,
                         penalty = .5)
shape.form <- shape ~ rb(lon, degree = 3, knots = knots.lon,
                         penalty = .4)

##  1- Fit a max-stable process
schlather <- fitmaxstab(ms1, locations, "whitmat", loc.form, scale.form,
                        shape.form, control = list(ndeps = rep(10^-4, 29)))
@ 

One can have a contour plot (Fig.~\ref{fig:mapGEV}) for the evolution
of the GEV parameters in $\mathbb{R}^d$ by invoking the following
code:
<<eval=FALSE,label=mapGEV>>=
par(mfrow=c(1,3))
map(schlather, "loc", col = rainbow(80))
title("Location")
map(schlather, "scale", col = heat.colors(80))
title("Scale")
map(schlather, "shape", col = topo.colors(100))
title("Shape")
@ 

\begin{figure}
  \centering
<<fig=TRUE,echo=FALSE,height=6,width=8>>=
<<mapGEV>>
@ 
  \caption{Contour plots of the GEV parameters.}
  \label{fig:mapGEV}
\end{figure}
Note that tuning the option \verb|col| will allow users to choose an
appropriate color palette.

Fig.~\ref{fig:mapQ50} plots a map of the 50-year return level while
focusing on a specific part of the region under study:
<<eval=FALSE,label=mapQ50>>=
new.ranges <- cbind(c(5, 8), c(2, 9))
colnames(new.ranges) <- c("lon", "lat")

map(schlather, "quant", ret.per = 50 , ranges = new.ranges)
@ 
\begin{figure}
  \centering
<<fig=TRUE,echo=FALSE>>=
<<mapQ50>>
@ 
  \caption{Contour plot of the 50-year return level.}
  \label{fig:mapQ50}
\end{figure}



\appendix

\chapter{Density and Gradient Computations}
\label{cha:dens-grad-comp}

\section{The Smith's Characterisation}
\label{sec:smith-char}

Let us recall that the Smith's characterisation of a max-stable
process is given by:
\begin{equation}
  \label{eq:smith}
  \Pr[Z_1 \leq z_1, Z_2 \leq z_2] = \exp\left[-\frac{1}{z_1} \Phi
    \left(\frac{a}{2} + \frac{1}{a} \log \frac{z_2}{z_1} \right) -
    \frac{1}{z_2} \Phi \left(\frac{a}{2} + \frac{1}{a}
      \log\frac{z_1}{z_2} \right) \right]
\end{equation}
where $\Phi$ is the standard normal cumulative distribution function
and, for two locations \#1 and \#2  
\begin{equation*}
  a^2 = \Delta x^T \Sigma^{-1} \Delta x \quad \text{and} \quad 
  \Sigma = 
  \begin{bmatrix}
    cov_{11} & cov_{12}\\
    cov_{12} & cov_{22}
  \end{bmatrix}
\end{equation*}
where $\Delta x$ is the distance vector between location \#1 and
location \#2.

\subsection{Useful quantities}
\label{sec:usefull-quantities}

Computation of the density as well as the gradient of the density is
not difficult but ``heavy'' though. For computation facilities and to
help readers, we define:
\begin{eqnarray}
  \label{eq:1}
  c_1 = \frac{a}{2} + \frac{1}{a} \log \frac{z_2}{z_1} \quad
  \text{and} \quad
  c_2 = \frac{a}{2} + \frac{1}{a} \log \frac{z_1}{z_2}
\end{eqnarray}
From these definitions, we note that $c_1 + c_2 = a$.

\subsection{Density computation}
\label{sec:density-computation-smith}

From \eqref{eq:smith}, we note the standard normal distribution
appears. Consequently, we need to compute its derivatives at $c_1$ and
$c_2$ with respect to $z_1$ and $z_2$.
\begin{eqnarray}
  \label{eq:2}
  \frac{\partial c_1}{\partial z_1} = \frac{1}{a} \left(-
    \frac{z_2}{z_1^2} \frac{z_1}{z_2} \right) = -\frac{1}{az_1} &\qquad&
  \frac{\partial c_1}{\partial z_2} = \frac{1}{a} \frac{1}{z_1}
  \frac{z_1}{z_2} = \frac{1}{az_2}\\
  \frac{\partial c_2}{\partial z_1} = - \frac{\partial c_1}{\partial z_1}
  = \frac{1}{az_1} &\qquad&
  \frac{\partial c_2}{\partial z_2} = - \frac{\partial c_1}{\partial z_2}
  = - \frac{1}{az_2}  
\end{eqnarray}

As the normal distribution appears in the Smith's characterisation,
the following quantities will be useful:
\begin{eqnarray}
  \label{eq:6}
  \frac{\partial \Phi(c_1)}{\partial z_1} = \frac{\partial
    \Phi(c_1)}{\partial c_1}
  \frac{\partial c_1}{\partial z_1} =  -\frac{\varphi(c_1)}{az_1} &\qquad&
  \frac{\partial \Phi(c_1)}{\partial z_2} = \frac{\partial
    \Phi(c_1)}{\partial c_1}
  \frac{\partial c_1}{\partial z_2} =  \frac{\varphi(c_1)}{az_2}\\
  \frac{\partial \Phi(c_2)}{\partial z_1} = \frac{\partial \Phi(c_2)}{\partial c_2}
  \frac{\partial c_2}{\partial z_1} =  \frac{\varphi(c_2)}{az_1} &\qquad&
  \frac{\partial \Phi(c_2)}{\partial z_2} = \frac{\partial \Phi(c_2)}{\partial c_2}
  \frac{\partial c_2}{\partial z_2} =  -\frac{\varphi(c_2)}{az_2}\\
  \frac{\partial \varphi(c_1)}{\partial z_1} = \frac{\partial \varphi(c_1)}{\partial c_1}
  \frac{\partial c_1}{\partial z_1} = \frac{c_1 \varphi(c_1)}{az_1} &\qquad& 
  \frac{\partial \varphi(c_1)}{z_2} = \frac{\partial
    \varphi(c_1)}{\partial c_1} \frac{\partial c_1}{\partial z_2} = -
  \frac{c_1 \varphi(c_1)}{a z_2}\\
  \frac{\partial \varphi(c_2)}{\partial z_1} = \frac{\partial \varphi(c_2)}{\partial c_2}
  \frac{\partial c_2}{\partial z_1} = - \frac{c_2 \varphi(c_2)}{a z_1} &\qquad&
  \frac{\partial \varphi(c_2)}{\partial z_2} = \frac{\partial \varphi(c_2)}{\partial c_2}
  \frac{\partial c_2}{\partial z_2} = \frac{c_2 \varphi(c_2)}{a z_2}
\end{eqnarray}

Define
\begin{equation}
  \label{eq:3}
  A = \frac{1}{z_1}\Phi(c_1) \quad \text{and} \quad B = \frac{1}{z_2}\Phi(c_2)
\end{equation}
Consequently, $F(z_1, z_2) = exp(-A -B)$ and
\begin{equation}
  \label{eq:4}
  \frac{\partial F}{\partial z_1} (z_1, z_2) = - \left(\frac{\partial
      A}{\partial z_1} + \frac{\partial B}{\partial z_1} \right)
  F(z_1, z_2)\qquad
  \frac{\partial F}{\partial z_2} (z_1, z_2) = - \left(\frac{\partial
      A}{\partial z_2} + \frac{\partial B}{\partial z_2} \right)
  F(z_1, z_2)
\end{equation}
By noting that
\begin{eqnarray}
  \label{eq:5}
  \frac{\partial A}{\partial z_1} &=& -\frac{\Phi(c_1)}{z_1^2} +
  \frac{1}{z_1} \left(-\frac{\varphi(c_1)}{az_1}\right) =
  -\frac{\Phi(c_1)}{z_1^2} - \frac{\varphi(c_1)}{az_1^2}\\
  \frac{\partial B}{\partial z_1} &=& \frac{1}{z_2}
  \frac{\varphi(c_2)}{az_1} = \frac{\varphi(c_2)}{az_1z_2}\\
  \frac{\partial A}{\partial z_2} &=& \frac{1}{z_1}
  \frac{\varphi(c_1)}{az_2} = \frac{\varphi(c_1)}{az_1z_2}\\
  \frac{\partial B}{\partial z_2} &=& -\frac{\Phi(c_2)}{z_2^2} +
  \frac{1}{z_2} \left(- \frac{\varphi(c_2)}{az_2}\right) =
  -\frac{\Phi(c_2)}{z_2^2} - \frac{\varphi(c_2)}{az_2^2}
\end{eqnarray}
and
\begin{eqnarray}
  \label{eq:10}
  \frac{\partial^2 A}{\partial z_2 \partial z_1} &=& 
  \frac{\partial }{\partial z_2} \left(-\frac{\Phi(c_1)}{z_1^2} -
    \frac{\varphi(c_1)}{az_1^2}\right) = -\frac{\varphi(c_1)}{a z_1^2
    z_2} + \frac{c_1\varphi(c_1)}{a^2 z_1^2 z_2} = -\frac{c_2
    \varphi(c_1)}{a^2z_1^2z_2}\\
  \frac{\partial^2 B}{\partial z_2 \partial z_1} &=& \frac{\partial
  }{\partial z_2} \frac{\varphi(c_2)}{az_1z_2} =
  -\frac{c_1\varphi(c_2)}{a^2z_1z_2^2}
\end{eqnarray}
So that,
\begin{eqnarray}
  \label{eq:7}
  \frac{\partial F}{\partial z_1} (z_1, z_2) &=&  \left(
    \frac{\Phi(c_1)}{z_1^2} + \frac{\varphi(c_1)}{az_1^2} -
    \frac{\varphi(c_2)}{az_1z_2} \right) F(z_1, z_2)\\
  \frac{\partial F}{\partial z_2} (z_1, z_2) &=& \left(
    \frac{\Phi(c_2)}{z_2^2} + \frac{\varphi(c_2)}{az_2^2}
    -\frac{\varphi(c_1)}{az_1z_2} \right) F(z_1, z_2)
\end{eqnarray}
Finally,
\begin{equation}
  \label{eq:9}
  \frac{\partial^2 F}{\partial z_2 \partial z_1} (z_1,
  z_2) = - \left(\frac{\partial^2 A}{\partial z_2 \partial z_1} +
    \frac{\partial^2 B}{\partial z_2 \partial z_1} \right) F(z_1, z_2)
  - \left(\frac{\partial A}{\partial z_1} + \frac{\partial B}{\partial
      z_1} \right) \frac{\partial F}{\partial z_2} (z_1, z_2)
\end{equation}
Thus, it leads to the following relation:
\begin{equation}
  \label{eq:11}
  f(z_1, z_2) = \left[ \frac{c_2 \varphi(c_1)}{a^2z_1^2z_2} + \frac{c_1
      \varphi(c_2)}{a^2z_1z_2^2} + \left(\frac{\Phi(c_1)}{z_1^2} +
      \frac{\varphi(c_1)}{az_1^2} - \frac{\varphi(c_2)}{az_1z_2} \right)
    \left(\frac{\Phi(c_2)}{z_2^2} + \frac{\varphi(c_2)}{az_2^2} -
      \frac{\varphi(c_1)}{az_1z_2} \right) \right] F(z_1, z_2)
\end{equation}

\subsection{Gradient computation}
\label{sec:gradient-computation-smith}

As said in section \ref{sec:assess-uncert}, the maximum pairwise
likelihood estimator $\psi_p$ satisfies:
\begin{equation*}
  \psi_p \sim \mathcal{N}\left(\psi, H^{-1} J H^{-1}\right)
\end{equation*}
where $H$ is the Fisher information matrix and $J$ the gradient of the
log pairwise likelihood.

This section aims to derive analytical form for $J$.

Let us recall that the log pairwise likelihood is defined by:
\begin{equation*}
  \ell_p(\mathbf{z}, \Psi) = \sum_{k = 1}^{n_{obs}}
  \sum_{i=1}^{n_{site}-1} \sum_{j=i+1}^{n_{site}} \log f(z_k^{(i)},
  z_k^{(j)})
\end{equation*}
where $n_{obs}$ is the number of observations, $\mathbf{z}_k =
(z_k^{(1)}, \ldots, z_k^{(n_{site})})$ is the $k$-th observation vector,
$n_{site}$ is the number of site within the region and $f$ is the
bivariate density.

Consequently, the gradient of the log pairwise density is given by:
\begin{equation*}
  \nabla \ell_p(\Psi) = \sum_{i=1}^{n_{site}-1}
  \sum_{j=i+1}^{n_{site}} \nabla \log f(z_k^{(i)}, z_k^{(j)})
\end{equation*}

Define:
\begin{eqnarray*}
  A &=& - \frac{\Phi(c1)}{z_1} - \frac{\Phi(c2)}{z_2}\\
  B &=& \frac{\Phi(c_2)}{z_2^2} + \frac{\varphi(c_2)}{az_2^2} -
  \frac{\varphi(c_1)}{az_1z_2}\\
  C &=& \frac{\Phi(c_1)}{z_1^2} + \frac{\varphi(c_1)}{az_1^2} -
  \frac{\varphi(c_2)}{az_1z_2}\\
  D &=& \frac{c_2 \varphi(c_1)}{a^2z_1^2z_2} + \frac{c_1
    \varphi(c_2)}{a^2z_1z_2^2}  
\end{eqnarray*}
so that,
\begin{equation*}
  \log f(z_k^{(i)}, z_k^{(j)}) = A + log(B C + D)
\end{equation*}

\subsubsection{With Unit Fréchet Margins}
\label{sec:with-unit-frechet}

For clarity purposes, let start our computations assuming that the
observations have unit Fréchet margins. For this special case, the
logarithm of the bivariate density $f$ is only a function of the
Mahalanobis distance $a$, the gradient w.r.t. the covariance matrix
elements $cov_{11}$, $cov_{12}$ and $cov_{22}$ is given through the
following relation\footnote{algebra operators are defined
  component-wise.}:
\begin{equation*}
  \nabla_\Sigma \log f(z_k^{(i)}, z_k^{(j)}) = \frac{\partial}{\partial a}
  \log f(z_k^{(i)}, z_k^{(j)}) {\nabla_\Sigma a}^T
\end{equation*}
where $\nabla_\Sigma a$ is the gradient of the Mahalanobis distance
w.r.t. the covariance matrix element i.e. $( \frac{\partial
  a}{\partial cov_{11}}, \frac{\partial a}{\partial cov_{12}},
\frac{\partial a}{\partial cov_{22}})$.

For clarity purposes, we first compute the following quantities:
\begin{eqnarray*}
  \frac{\partial c_1}{\partial a} = \frac{1}{2} - \frac{1}{a^2} \log
  \frac{z_2}{z_1} = \frac{c_2}{a} &\qquad& \frac{\partial c_2}{\partial
    a} = \frac{c_1}{a}\\
  \frac{\partial \Phi(c_1)}{\partial a} = \frac{\partial
    \Phi(c_1)}{\partial c_1} \frac{\partial c_1}{\partial a} =
  \frac{c_2 \varphi(c_1)}{a} &\qquad& \frac{\partial
    \Phi(c_2)}{\partial a} = \frac{c_1 \varphi(c_2)}{a}\\
  \frac{\partial \varphi(c_1)}{\partial a} = \frac{\partial
    \varphi(c_1)}{\partial c_1} \frac{\partial c_1}{\partial a} =
  -\frac{c_1c_2 \varphi(c_1)}{a} &\qquad& \frac{\partial
    \varphi(c_2)}{\partial a} = -\frac{c_1c_2 \varphi(c_2)}{a}\\
  \frac{\partial c_2\varphi(c_1)}{\partial a} = \frac{c_1(1 -
    c_2^2)\varphi(c_1)}{a} &\qquad& \frac{\partial
    c_1\varphi(c_2)}{\partial a} = \frac{(1-c_1^2)c_2\varphi(c_2)}{a}
\end{eqnarray*}

Consequently, we have:
\begin{eqnarray*}
  dA_a &=& \frac{\partial A}{\partial a} = - \frac{1}{z_1} \frac{c_2
    \varphi(c_1)}{a} - \frac{1}{z_2} \frac{c_1 \varphi(c_2)}{a} =
  -\frac{c_2 \varphi(c_1)}{az_1} - \frac{c_1 \varphi(c_2)}{az_2}\\
  dC_a &=& \frac{\partial C}{\partial a} = \frac{1}{z_1^2} \frac{c_2
    \varphi(c_1)}{a} + \frac{1}{z_1^2}
  \frac{-\frac{c_1c_2\varphi(c_1)}{a} a  - \varphi(c_1)}{a^2} -
  \frac{1}{z_1z_2} \frac{-\frac{c_1c_2 \varphi(c_2)}{a}a -
    \varphi(c_2)}{a^2}\\
  &=& \frac{c_2 \varphi(c_1)}{az_1^2} -
  \frac{(1+c_1c_2)\varphi(c_1)}{a^2z_1^2} +
  \frac{(1+c_1c_2)\varphi(c_2)}{a^2z_1z_2}\\
  &=& \frac{\left[c_2(a - c_1)-1\right] \varphi(c_1)}{a^2z_1^2} +
  \frac{(1+c_1c_2)\varphi(c_2)}{a^2z_1z_2}\\
  &=& \frac{(c_2^2 - 1) \varphi(c_1)}{a^2z_1^2} +
  \frac{(1+c_1c_2)\varphi(c_2)}{a^2z_1z_2}\\
  dB_a &=& \frac{\partial B}{\partial a} = \frac{(c_1^2 - 1)
    \varphi(c_2)}{a^2z_2^2} +
  \frac{(1+c_1c_2)\varphi(c_1)}{a^2z_1z_2}\\
  dD_a &=& \frac{\partial D}{\partial a} = \frac{1}{z_1^2z_2}\frac{\frac{c_1(1 -
      c_2^2)\varphi(c_1)}{a}a^2 - 2a c_2\varphi(c_1)}{a^4} +
  \frac{1}{z_1z_2^2}\frac{\frac{(1-c1^2)c_2\varphi(c_2)}{a}a^2 - 2a
    c_1\varphi(c_2)}{a^4}\\
  &=& \frac{(c_1- 2 c_2 - c_1c_2^2) \varphi(c_1)}{a^3z_1^2z_2} +
  \frac{(c_2- 2 c_1 - c_1^2c_2) \varphi(c_2)}{a^3z_1z_2^2}
\end{eqnarray*}

Finally,
\begin{equation*}
  \nabla_\Sigma \log f(x_k^{(i)}, x_k^{(j)}) = \left[dA_a + \frac{(C
      dB_a + B dC_a +dD_a)}{BC + D} \right] \cdot{\nabla_\Sigma a}^T
\end{equation*}

\subsubsection{With Ordinary GEV Margins}
\label{sec:with-ordinary-gev}

In the previous section, we derived the gradient assuming unit Fréchet
margins. Now, we consider the more general case where margins are
supposed to be ordinary GEV. 

We have to be aware that the bivariate density changes when we do not
suppose unit Fréchet margins anymore. For instance, the bivariate
density evaluated at two observations $y_1$ and $y_2$ with ordinary
GEV margins is given by:
\begin{equation}
  \label{eq:densSmithOrdGEV}
  f(y_1,y_2) = f(z_1, z_2) |J(y_1, y_2)|
\end{equation}
where $z_1$ (resp. $z_2$) is the transformation of $y_1$ (resp. $y_2$)
to the unit Fréchet scale and $|J(y_1, y_2)|$ is the determinant of
the Jacobian related to the transformation $(y_1,y_2) \mapsto
(z_1,z_2)$.

For clarity purpose, we can write the logarithm of the bivariate
density as follows:
\begin{equation*}
  \log f(y_1,y_2) = A + \log \left(BC + D\right) + E
\end{equation*}
where $E = \log |J(y_1, y_2)|$ and the quantities $A$,
$B$, $C$ and $D$ are the same as in the previous section.

The transformation from $y_i$ to $z_i$ is given by:
\begin{equation}
  z_i = \left(1 + \xi_i \frac{y_i - \mu_i}{\sigma_i}
  \right)_+^{\frac{1}{\xi_i}}
\end{equation}
where $\mu_i$, $\sigma_i$ and $\xi_i$ are the GEV location, scale and
shape parameters and $x_+ = \min(0,x)$.

Consequently, we need a response surface
(see section~\ref{sec:with-unknown-gev}) to model the evolution of the
GEV parameters in space. Let suppose that we have a polynomial
response surface for each GEV parameter, one can write:
\begin{eqnarray}
  \label{eq:polynomSurface}
  \mu &=& X_\mu \beta_\mu\\
  \sigma &=& X_\sigma \beta_\sigma\\
  \xi &=& X_\xi \beta_\xi
\end{eqnarray}
where $\mu = (\mu_1, \ldots, \mu_{n_{site}})$, $\sigma = (\sigma_1,
\ldots, \sigma_{n_{site}})$ and $\xi = (\xi_1, \ldots,
\xi_{n_{site}})$ are the vector for the location, scale and shape GEV
parameters for all the sites within the region study, $X_\mu$,
$X_\sigma$ and $X_\xi$ are the design matrices for each GEV parameters
and $\beta_\mu$, $\beta_\sigma$ and $\beta_\xi$ are the regression
coefficients to be estimated.

Consequently, from one ordinary GEV observation $\mathbf{y}$, one can
transform it to unit Fréchet margins using the following
transformation:
\begin{equation}
  \label{eq:gev2frech}
  \mathbf{z}_i=\left\{1+\frac{X^{(i)}_\xi
      \beta_\xi(\mathbf{y}_i -X^{(i)}_\mu
      \beta_\mu)}{X^{(i)}_\sigma \beta_\sigma}\right\}^{1/(X^{(i)}_\xi
    \beta_\xi)}, \qquad i=1,\ldots,n_{site} 
\end{equation}
where $X^{(i)}$ stands for the $i$-th row of the design matrix $X$ and
$\mathbf{z}_i$ denotes the $i$-th element of the vector
$\mathbf{z}$.

Consequently, $|J(y_1, y_2)|$ is given by:
\begin{equation}
  \label{eq:jacGev2frech}
  |J(y_1, y_2)| = \frac{1}{X^{(i)}_\sigma \beta_\sigma X^{(j)}_\sigma
    \beta_\sigma} \left(1 + X^{(i)}_\xi \beta_\xi \frac{y_i -
      X^{(i)}_\mu \beta_\mu}{X^{(i)}_\sigma \beta_\sigma}
  \right)_+^{\frac{1}{X^{(i)}_\xi \beta_\xi}-1} \left(1 +
    X^{(j)}_\xi \beta_\xi \frac{y_2 - X^{(j)}_\mu
      \beta_\mu}{X^{(j)}_\sigma \beta_\sigma}
  \right)_+^{\frac{1}{X^{(j)}_\xi \beta_\xi}-1}
\end{equation}


It is easy to see that:
\begin{eqnarray*}
  \frac{\partial \mathbf{z}_i}{\partial \beta_\mu} &=&
  -\frac{\mathbf{z}_i^{1 - X^{(i)}_\xi \beta_\xi} X^{(i)}_\mu}{
    X^{(i)}_\sigma \beta_\sigma}\\
  &=& -\frac{\mathbf{z}_i^{1-\xi_i}}{\sigma_i}\cdot
  X^{(i)}_\mu\\
  \frac{\partial \mathbf{z}_i}{\partial \beta_\sigma} &=&
  -\frac{\mathbf{z}_i^{1 - X^{(i)}_\xi \beta_\xi}
    \left(\mathbf{y}_i - X^{(i)}_\mu
      \beta_\mu\right)}{X^{(i)}_\sigma \beta^2_\sigma}\\
  &=& - \frac{\mathbf{z}_i^{1-\xi_i} \left(\mathbf{y}_i -
      \mu_i \right)}{\sigma_i} \cdot \frac{1}{\beta_\sigma}\\ 
  \frac{\partial \mathbf{z}_i}{\partial \beta_\xi} &=& -
  \frac{\mathbf{z}_i \log \mathbf{z}_i}{\beta_\xi} +
  \frac{\mathbf{z}^{(i)} \left(\mathbf{y}_i - X^{(i)}_\mu
      \beta_\mu\right)}{\beta_\xi X^{(i)}_\sigma \beta_\sigma
    \mathbf{z}_i^{X^{(i)}_\xi \beta_\xi}}\\
  &=& \left[ \mathbf{z}_i^{1 - \xi_i}
    \frac{\left(\mathbf{y}_i - \mu_i\right)}{\sigma_i} -
    \mathbf{z}_i \log \mathbf{z}_i\right] \cdot
  \frac{1}{\beta_\xi}
  % \frac{\partial c_1}{\partial \beta_\mu} &=& \frac{1}{a}
%   \left(\frac{X^{(i)}_\mu}{X^{(i)}_\sigma \beta_\sigma
%       (\mathbf{z}^{(i)})^{X^{(i)}_\xi \beta_\xi}} -
%     \frac{X^{(j)}_\mu}{X^{(j)}_\sigma \beta_\sigma
%       (\mathbf{z}^{(j)})^{X^{(j)}_\xi \beta_\xi}} \right)\\
%   &=& \frac{1}{a \sigma_i (\mathbf{z}^{(i)})^{\xi_i}} \cdot X^{(i)}_\mu
%   - \frac{1}{a \sigma_j (\mathbf{z}^{(j)})^{\xi_j}} \cdot X^{(j)}_\mu\\
%   \frac{\partial c_1}{\partial \beta_\sigma} &=& \frac{1}{a}
%   \left(\frac{\mathbf{y}^{(i)} - X^{(i)}_\mu \beta_\mu}{X^{(i)}_\sigma
%       \beta^2_\sigma (\mathbf{z}^{(i)})^{X^{(i)}_\xi \beta_\xi}} -
%     \frac{\mathbf{y}^{(j)} - X^{(j)}_\mu \beta_\mu}{X^{(j)}_\sigma
%       \beta^2_\sigma (\mathbf{z}^{(j)})^{X^{(j)}_\xi \beta_\xi}}
%   \right)\\
%   &=& \frac{1}{a} \left[\frac{\mathbf{y}^{(i)} - \mu_i}{\sigma_i
%       (\mathbf{z}^{(i)})^{\xi_i}} - \frac{\mathbf{y}^{(j)} -
%       \mu_j}{\sigma_j (\mathbf{z}^{(j)})^{\xi_j}} \right] \cdot
%   \frac{1}{\beta_\sigma}\\
%   \frac{\partial c_1}{\partial \beta_\xi} &=& \frac{1}{a}
%   \left[\frac{\log \mathbf{z}^{(i)}}{\beta_\xi} -
%     \frac{\mathbf{y}^{(i)} - X^{(i)}_\mu \beta_\mu}{\beta_\xi
%       X^{(i)}_\sigma \beta_\sigma (\mathbf{z}^{(i)})^{X^{(i)}_\xi
%         \beta_\xi}} - \frac{\log \mathbf{z}^{(j)}}{\beta_\xi} +
%     \frac{\mathbf{y}^{(j)} - X^{(j)}_\mu \beta_\mu}{\beta_\xi
%       X^{(j)}_\sigma \beta_\sigma (\mathbf{z}^{(j)})^{X^{(j)}_\xi
%         \beta_\xi}}\right]\\
%   &=& \frac{1}{a} \left[\log \frac{\mathbf{z}^{(i)}}{\mathbf{z}^{(j)}}
%     + \frac{\mathbf{y}^{(j)} - \mu_j}{\sigma_j
%       (\mathbf{z}^{(j)})^{\xi_j}}- \frac{\mathbf{y}^{(i)} -
%       \mu_i}{\sigma_i (\mathbf{z}^{(i)})^{\xi_i}} \right] \cdot
%   \frac{1}{\beta_\xi}
\end{eqnarray*}
where the operator $\cdot$ performs operations component-wise.
% Note that the partial derivatives for $c_2$ are easily obtained as:
% \begin{equation*}
%   \frac{\partial c_2}{\partial \beta_\mu} = - \frac{\partial
%     c_1}{\partial \beta_\mu}, \quad \frac{\partial c_2}{\partial
%     \beta_\sigma} = - \frac{\partial c_1}{\partial \beta_\sigma},
%   \quad \frac{\partial c_2}{\partial \beta_\xi} = - \frac{\partial
%     c_1}{\partial \beta_\xi}
% \end{equation*}

To obtain the gradient of the logarithm of the bivariate density, we
need to compute the partial derivatives of $A$, $B$, $C$, $D$ and $E$
w.r.t. $\beta_\mu$, $\beta_\sigma$ and $\beta_\xi$.
% \begin{eqnarray*}
%   \frac{\partial \Phi(c_1)}{\partial \beta_\mu} &=& \frac{\partial
%     \Phi(c_1)}{\partial c_1} \frac{\partial c_1}{\partial \beta_\mu}\\
%   &=&
%   \frac{\varphi(c_1)}{a \sigma_i (\mathbf{z}^{(i)})^{\xi_i}} \cdot
%   X^{(i)}_\mu - \frac{\varphi(c_1)}{a \sigma_j
%     (\mathbf{z}^{(j)})^{\xi_j}} \cdot X^{(j)}_\mu\\
%   \frac{\partial \Phi(c_2)}{\partial \beta_\mu} &=& \frac{\varphi(c_2)}{a
%     \sigma_j (\mathbf{z}^{(j)})^{\xi_j}} \cdot X^{(j)}_\mu -
%   \frac{\varphi(c_2)}{a \sigma_i (\mathbf{z}^{(i)})^{\xi_i}} \cdot
%   X^{(i)}_\mu\\
%   \frac{\partial \Phi(c_1)}{\partial \beta_\sigma} &=& \frac{\partial
%     \Phi(c_1)}{\partial c_1} \frac{\partial c_1}{\partial
%     \beta_\sigma}\\
%   &=& \frac{\varphi(c_1)}{a} \left[\frac{\mathbf{y}^{(i)} -
%       \mu_i}{\sigma_i (\mathbf{z}^{(i)})^{\xi_i}} -
%     \frac{\mathbf{y}^{(j)} - \mu_j}{\sigma_j
%       (\mathbf{z}^{(j)})^{\xi_j}} \right] \cdot
%   \frac{1}{\beta_\sigma}\\
%   \frac{\partial \Phi(c_2)}{\partial \beta_\sigma} &=&
%   \frac{\varphi(c_2)}{a} \left[\frac{\mathbf{y}^{(j)} - \mu_j}{\sigma_j
%       (\mathbf{z}^{(j)})^{\xi_j}} - \frac{\mathbf{y}^{(i)} -
%       \mu_i}{\sigma_i (\mathbf{z}^{(i)})^{\xi_i}} \right] \cdot
%   \frac{1}{\beta_\sigma}\\
%   \frac{\partial \Phi(c_1)}{\partial \beta_\xi} &=& \frac{\partial 
%     \Phi(c_1)}{\partial c_1} \frac{\partial c_1}{\partial \beta_\xi}\\
%   &=&
%   \frac{\varphi(c_1)}{a} \left[\log \frac{\mathbf{z}^{(i)}}{\mathbf{z}^{(j)}}
%     + \frac{\mathbf{y}^{(j)} - \mu_j}{\sigma_j
%       (\mathbf{z}^{(j)})^{\xi_j}}- \frac{\mathbf{y}^{(i)} -
%       \mu_i}{\sigma_i (\mathbf{z}^{(i)})^{\xi_i}} \right] \cdot
%   \frac{1}{\beta_\xi} \\
%   \frac{\partial \Phi(c_2)}{\partial \beta_\xi} &=&
%   \frac{\varphi(c_2)}{a} \left[\log
%     \frac{\mathbf{z}^{(j)}}{\mathbf{z}^{(i)}} + \frac{\mathbf{y}^{(i)}
%       - \mu_i}{\sigma_i (\mathbf{z}^{(i)})^{\xi_i}}-
%     \frac{\mathbf{y}^{(j)} - \mu_j}{\sigma_j
%       (\mathbf{z}^{(j)})^{\xi_j}} \right] \cdot \frac{1}{\beta_\xi}\\
%   \frac{\partial \varphi(c_1)}{\partial \beta_\mu} &=& \frac{\partial 
%     \varphi(c_1)}{\partial c_1} \frac{\partial c_1}{\partial \beta_\mu}\\
%   &=&
%   - \frac{c_1 \varphi(c_1)}{a \sigma_i (\mathbf{z}^{(i)})^{\xi_i}} \cdot
%   X^{(i)}_\mu + \frac{c_1 \varphi(c_1)}{a \sigma_j
%     (\mathbf{z}^{(j)})^{\xi_j}} \cdot X^{(j)}_\mu\\ 
%   \frac{\partial \varphi(c_2)}{\partial \beta_\mu} &=& \frac{\partial 
%     \varphi(c_2)}{\partial c_2} \frac{\partial c_2}{\partial \beta_\mu}\\
%   &=&
%   \frac{c_2 \varphi(c_2)}{a \sigma_i (\mathbf{z}^{(i)})^{\xi_i}} \cdot
%   X^{(i)}_\mu - \frac{c_2 \varphi(c_2)}{a \sigma_j
%     (\mathbf{z}^{(j)})^{\xi_j}} \cdot X^{(j)}_\mu\\
%   \frac{\partial \varphi(c_1)}{\partial \beta_\sigma} &=& \frac{\partial 
%     \varphi(c_1)}{\partial c_1} \frac{\partial c_1}{\partial
%     \beta_\sigma}\\
%   &=& - \frac{c_1 \varphi(c_1)}{a}
%   \left[\frac{\mathbf{y}^{(i)} - \mu_i}{\sigma_i
%       (\mathbf{z}^{(i)})^{\xi_i}} - \frac{\mathbf{y}^{(j)} -
%       \mu_j}{\sigma_j (\mathbf{z}^{(j)})^{\xi_j}} \right] \cdot
%   \frac{1}{\beta_\sigma}\\
%   \frac{\partial \varphi(c_2)}{\partial \beta_\sigma} &=& \frac{c_2
%     \varphi(c_2)}{a} \left[\frac{\mathbf{y}^{(i)} - \mu_i}{\sigma_i
%       (\mathbf{z}^{(i)})^{\xi_i}} - \frac{\mathbf{y}^{(j)} -
%       \mu_j}{\sigma_j (\mathbf{z}^{(j)})^{\xi_j}} \right] \cdot
%   \frac{1}{\beta_\sigma}\\
%   \frac{\partial \varphi(c_1)}{\partial \beta_\xi} &=& \frac{\partial
%     \varphi(c_1)}{\partial c_1} \frac{\partial c_1}{\partial \beta_\xi}\\
%   &=&
%   - \frac{c_1 \varphi(c_1)}{a} \left[\log
%     \frac{\mathbf{z}^{(i)}}{\mathbf{z}^{(j)}} + \frac{\mathbf{y}^{(j)}
%       - \mu_j}{\sigma_j (\mathbf{z}^{(j)})^{\xi_j}}-
%     \frac{\mathbf{y}^{(i)} - \mu_i}{\sigma_i
%       (\mathbf{z}^{(i)})^{\xi_i}} \right] \cdot \frac{1}{\beta_\xi}\\
%   \frac{\partial \varphi(c_2)}{\partial \beta_\xi} &=& \frac{c_2
%     \varphi(c_2)}{a} \left[\log \frac{\mathbf{z}^{(i)}}{\mathbf{z}^{(j)}}
%     + \frac{\mathbf{y}^{(j)} - \mu_j}{\sigma_j
%       (\mathbf{z}^{(j)})^{\xi_j}}- \frac{\mathbf{y}^{(i)} -
%       \mu_i}{\sigma_i (\mathbf{z}^{(i)})^{\xi_i}} \right] \cdot
%   \frac{1}{\beta_\xi}
% \end{eqnarray*}

For shortness, we do it in ``one step'' with the convention $\beta =
(\beta_\mu, \beta_\sigma, \beta_\xi)$.
\begin{eqnarray*}
  \frac{\partial A}{\partial \beta} &=& \frac{\partial A}{\partial z_1}
  \cdot \nabla_\beta z_1 + \frac{\partial A}{\partial z_2} \cdot
  \nabla_\beta z_2\\
  \frac{\partial B}{\partial \beta} &=& \frac{\partial B}{\partial z_1}
  \cdot \nabla_\beta z_1 + \frac{\partial B}{\partial z_2} \cdot
  \nabla_\beta z_2\\
  \frac{\partial C}{\partial \beta} &=& \frac{\partial C}{\partial z_1}
  \cdot \nabla_\beta z_1 + \frac{\partial C}{\partial z_2} \cdot
  \nabla_\beta z_2\\
  \frac{\partial D}{\partial \beta} &=& \frac{\partial D}{\partial z_1}
  \cdot \nabla_\beta z_1 + \frac{\partial D}{\partial z_2} \cdot
  \nabla_\beta z_2\\
\end{eqnarray*}
where $\nabla_\beta z_1$ (resp. $\nabla_\beta z_2$) is the gradient of
$z_1$ (reps. $z_2$) w.r.t. $\beta$ and the partial derivatives of $A$,
$B$, $C$ and $D$ w.r.t. $z_1$ are given by the following equations:
\begin{eqnarray*}
  dA_{z_1} &=& \frac{\partial A}{\partial z_1} = \frac{\varphi(c_1) +
    a \Phi(c_1)}{a z_1^2} - \frac{\varphi(c_2)}{a z_1 z_2}\\
  dB_{z_1} &=& \frac{\partial B}{\partial z_1} = \frac{c_1
    \varphi(c_2)}{a^2 z_1 z_2^2} + \frac{c_2 \varphi(c_1)}{a^2 z_1^2
    z_2}\\
  dC_{z_1} &=& \frac{\partial C}{\partial z_1} = \frac{(a + c_2)
    \varphi(c_2)}{a^2 z_1^2 z_2} - \frac{2\Phi(c_1)}{z_1^3} -
  \frac{(2a+c_2)\varphi(c_1)}{a^2z_1^3}\\
  dD_{z_1} &=& \frac{\partial D}{\partial z_1} = \frac{\left[1 - c_2
      (a + c_2) \right] \varphi(c_1)}{a^2 z_1^3 z_2} - \frac{\left[1 +
    c_1 (a + c_2) \right] \varphi(c_2)}{a^3 z_1^2 z_2^2}
\end{eqnarray*}
while the partial derivatives of $A$, $B$, $C$ and $D$ w.r.t. $z_2$
are given by:
\begin{eqnarray*}
  dA_{z_2} &=& \frac{\partial A}{\partial z_2} = \frac{\varphi(c_2) +
    a \Phi(c_2)}{a z_2^2} - \frac{\varphi(c_1)}{a z_1 z_2}\\
  dB_{z_2} &=& \frac{\partial B}{\partial z_2} = \frac{(a + c_1)
    \varphi(c_1)}{a^2 z_1 z_2^2} - \frac{2\Phi(c_2)}{z_2^3} -
  \frac{(2a+c_1)\varphi(c_2)}{a^2z_2^3}\\
  dC_{z_2} &=& \frac{\partial C}{\partial z_2} = \frac{c_1
    \varphi(c_2)}{a^2 z_1 z_2^2} + \frac{c_2 \varphi(c_1)}{a^2 z_1^2
    z_2}\\
  dD_{z_2} &=& \frac{\partial D}{\partial z_2} = \frac{\left[1 - c_1
      (a + c_1) \right] \varphi(c_2)}{a^2 z_1 z_2^3} - \frac{\left[1 +
    c_2 (a + c_1) \right] \varphi(c_1)}{a^3 z_1^2 z_2^2}
\end{eqnarray*}

For the Jacobian part $E$, we have:
\begin{eqnarray*}
  dE_\mu &=& \frac{\partial E}{\partial \beta_\mu} = 
  \frac{\xi_1-1}{\sigma_1 z_1^{\xi_1}} \cdot X^{(1)}_\mu +
  \frac{\xi_2-1}{\sigma_2 z_2^{\xi_2}} \cdot X^{(2)}_\mu\\
  dE_\sigma &=& \frac{\partial E}{\partial \beta_\sigma} =  \left(
    \frac{(y_1 - \mu_1)(\xi_1-1)}{\sigma_1z_1^{\xi_1}} +
    \frac{(y_2-\mu_2)(\xi_2-2)}{\sigma_2 z_2^{\xi_2}} + 2\right)
  \cdot \frac{1}{\beta_\sigma}\\
  dE_\xi &=& \frac{\partial E}{\partial \beta_\xi} =
  \frac{(1-\xi_1)(y_1 - \mu_1)}{\sigma_1 \xi_1 z_1^{\xi_1}} \cdot
  X^{(1)}_\xi + \frac{(1-\xi_2)(y_2 - \mu_2)}{\sigma_2 \xi_2
    z_2^{\xi_2}} \cdot X^{(2)}_\xi - \log z_1 \cdot
  \frac{1}{\beta_\xi} - \log z_2 \frac{1}{\beta_\xi}\\
\end{eqnarray*}

Finally, we have:
\begin{equation}
  \nabla_\beta \log f(y_1,y_2) = \frac{\partial A}{\partial \beta} +
  \frac{C \frac{\partial B}{\partial \beta} + B \frac{\partial
      C}{\partial \beta}}{BC + D} + \frac{\partial E}{\partial \beta}  
\end{equation}
where
\begin{equation*}
  \frac{\partial E}{\partial \beta} = (dE_\mu, dE_\sigma, dE_\xi)^T  
\end{equation*}


\section{The Schlather's Characterisation}
\label{sec:schlather-char}

The Schlather's characterisation of a max-stable process is given by:
\begin{equation}
  \label{eq:schlather}
  \Pr[Z_1 \leq z_1, Z_2 \leq z_2] = \exp\left[-\frac{1}{2}
    \left(\frac{1}{z_1} + \frac{1}{z_2} \right) \left(1 + \sqrt{1 - 2
        (\rho(h) + 1) \frac{z_1 z_2}{(z_1 + z_2)^2}} \right) \right]
\end{equation}
where $h$ is the distance between location \#1 and location \#2 and
$\rho(h)$ is a valid correlation function such as $-1 \leq \rho(h)
\leq 1$.

\subsection{Density computation}
\label{sec:density-computation-schlather}

Computation of the density as well as the gradient of the density is
not difficult but ``heavy'' though.

By noting that, 
\begin{equation*}
  \frac{\partial^2 }{\partial z_1 \partial z_2} \exp(V(z_1, z_2)) =
  \left[\frac{\partial^2}{\partial z_1 \partial z_2} V(z_1, z_2) +
    \left(\frac{\partial }{\partial z_1} V(z_1, z_2) \right)
    \left(\frac{\partial }{\partial z_2} V(z_1, z_2) \right) \right]
  \exp(V(z_1, z_2))
\end{equation*}
where $V(z_1, z_2)$ is any function in $\mathcal{C}^2$.

Consequently, to compute the (bivariate) density, we only need to
compute the partial derivatives and the mixed partial derivatives. For
our case, it turns out to be:

\begin{equation*}
  V(z_1, z_2) = -\frac{1}{2} \left(\frac{1}{z_1} + \frac{1}{z_2} \right)
  \left(1 + \sqrt{1 - 2 (\rho(h) + 1) \frac{z_1 z_2}{(z_1 + z_2)^2}}
  \right)
\end{equation*}


\begin{equation*}
  \frac{\partial}{\partial z_1} V(z_1, z_2) = -\frac{\rho(h) z_1 -
    c1 - z_2}{2 c_1 z_1^2} \quad
  \frac{\partial}{\partial z_2} V(z_1, z_2) = -\frac{\rho(h) z_2 -
    c1 - z_1}{2 c_1 z_2^2} \quad
  \frac{\partial^2}{\partial z_1\partial z_2} V(z_1, z_2) =
  \frac{1 - \rho(h)^2}{2 c_1^3}
\end{equation*}
where
\begin{equation*}
  c_1 = \sqrt{z_1^2 + z_2^2 - 2 z_1 z_2 \rho(h)}
\end{equation*}

Lastly,
\begin{equation}
  \label{eq:schlatherDens}
  f(z_1, z_2) = \left[ \frac{1 - \rho(h)^2}{2 c_1^3} +
    \left(-\frac{\rho(h) z_1 - c1 - z_2}{2 c_1 z_1^2} \right) \left(
      -\frac{\rho(h) z_2 - c1 - z_1}{2 c_1 z_2^2} \right) \right]
  \exp(V(z_1, z_2))
\end{equation}

\subsection{Gradient computation}
\label{sec:gradient-computation-schlather}

\subsubsection{With Unit Fréchet Margins}
\label{sec:with-unit-frechet-1}

From equation \eqref{eq:schlatherDens}, we have:
\begin{equation*}
  \log f(z_1, z_2) = A + \log(B + C D)
\end{equation*}
where
\begin{equation*}
  A =  V(z_1, z_2) \quad
  B = \frac{1 - \rho(h)^2}{2 c_1^3} \quad
  C = -\frac{\rho(h) z_1 - c1 - z_2}{2 c_1 z_1^2} \quad
  D = -\frac{\rho(h) z_2 - c1 - z_1}{2 c_1 z_2^2}
\end{equation*}

As the bivariate density is only a function of the covariance function
$\rho(h)$, we have:
\begin{equation*}
  \nabla \log f(z_1, z_2) = \frac{\partial}{\partial \rho(h)} \log
  f(z_1, z_2) \left(\nabla \rho(h) \right)^T
\end{equation*}
where $\nabla \rho(h)$ is the vector of the partial derivatives of the
covariance function $\rho(h)$ with respect to its parameters.

\begin{eqnarray*}
  dA_\rho &=& \frac{\partial A}{\partial \rho(h)} = \frac{1}{2c_1}\\
  dB_\rho &=& \frac{\partial B}{\partial \rho(h)}  = -\frac{\rho(h)}{c_1^3} +
  \frac{3(1 - \rho(h))z_1 z_2}{c_1^5}\\
  dC_\rho &=& \frac{\partial C}{\partial \rho(h)} = -\frac{z_1-z_2\rho(h)}{2
    c_1^3}\\
  dD_\rho &=& \frac{\partial D}{\partial \rho(h)} = -\frac{z_2-z_1\rho(h)}{2
    c_1^3}\\
\end{eqnarray*}
So that,
\begin{equation*}
  \nabla \log f(z_1, z_2) = \left[dA_\rho + \frac{(C dB_\rho + B
      dC_\rho + dD_\rho)}{BC + D} \right] \left(\nabla \rho(h)
  \right)^T
\end{equation*}

Note that when using the Whittle-Matérn covariance function, the
standard errors are not available if the \verb|smooth| parameter is
hand fixed because the Bessel function is not derivable w.r.t. this
parameter.

\subsubsection{With Ordinary GEV Margins}
\label{sec:with-ordinary-gev-1}

For the derivation of the gradient with ordinary GEV margins, most of
the computations have already been done in
Section~\ref{sec:with-ordinary-gev}. Especially, we only need to
compute the partial derivatives of $A$, $B$, $C$ and $D$ w.r.t. $z_1$
and $z_2$.

\begin{eqnarray*}
  dA_{z_1} &=& \frac{\partial A}{\partial z_1} = -\frac{\rho(h) z_1 -
    c1 - z_2}{2 c_1 z_1^2}\\
  dB_{z_1} &=& \frac{\partial B}{\partial z_1} = \frac{3 (\rho(h)^2 -
    1) (z_1 - \rho(h) z_2)}{2 c_1^5}\\
  dC_{z_1} &=& \frac{\partial C}{\partial z_1} = \frac{2z_1^3 \rho(h)
    + 6 z_1 z_2^2 \rho(h)^2 - 3 z_1^2 z_2 (1 + \rho(h)^2) - 2 c_1^3 -
    2 z_2^3}{2 c_1^3 z_1^3}\\
  dD_{z_1} &=& \frac{\partial C}{\partial z_2} = -\frac{(z_2 \rho(h) -
    c_1 - z_1) (z_2 \rho(h) + c1 - z_1)}{2 c_1^3 z_2^2}  
\end{eqnarray*}
and
\begin{eqnarray*}
  dA_{z_2} &=& \frac{\partial A}{\partial z_2} = -\frac{\rho(h) z_2 -
    c1 - z_1}{2 c_1 z_2^2}\\
  dB_{z_2} &=& \frac{\partial B}{\partial z_2} = \frac{3 (\rho(h)^2 -
    1) (z_2 - \rho(h) z_1)}{2 c_1^5}\\
  dC_{z_2} &=& \frac{\partial C}{\partial z_2} = -\frac{(z_1 \rho(h) -
    c_1 - z_2) (z_1 \rho(h) + c1 - z_2)}{2 c_1^3 z_1^2}\\
  dD_{z_2} &=& \frac{\partial D}{\partial z_2} = \frac{2z_2^3 \rho(h)
    + 6 z_1^2 z_2 \rho(h)^2 - 3 z_1 z_2^2 (1 + \rho(h)^2) - 2 c_1^3 -
    2 z_1^3}{2 c_1^3 z_2^3}
\end{eqnarray*}

Finally, we have:
\begin{equation}
  \nabla_\beta \log f(y_1,y_2) = \frac{\partial A}{\partial \beta} +
  \frac{C \frac{\partial B}{\partial \beta} + B \frac{\partial
      C}{\partial \beta}}{BC + D} + \frac{\partial E}{\partial \beta}  
\end{equation}
where $\frac{\partial A}{\partial \beta}$, $\frac{\partial B}{\partial
  \beta}$, $\frac{\partial C}{\partial \beta}$, $\frac{\partial
  D}{\partial \beta}$ and $\frac{\partial E}{\partial \beta}$ have
been already defined in Section~\ref{sec:with-ordinary-gev}.

\bibliography{biblio_ribatet}
\bibliographystyle{kluwer}
\end{document}

